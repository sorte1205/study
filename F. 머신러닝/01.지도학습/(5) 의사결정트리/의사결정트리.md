# 의사결정트리 (Decision Tree)

> 스무고개

## #01. 의사결정트리 개요

의사결정 규칙을 나무 구조로 도표화하여 일반화된 지식을 추출한다. 이를 통해 분류와 예측(회귀)을 수행한다. (회귀에서는 비추)

![tree](res/tree01.png)

### (1) 의사결정트리 구성

대표적으로 노드(Node), 가지(Branch), 깊이(Depth)로 구성

![img1](res/tree02.png)


| 구성요소 | 이름 | 내용 |
|---|---|---|
| Root Node | 뿌리마디 | 시작점 |
| Child Node | 자식마디 | 하나 이상의 노드로부터 분리되어 나간 2개 이상의 노드들 |
| Parent Node | 부모마디 | 특정 노드의 상위 노드 |
| Terminal Node | 끝마디 | 더이상 자식을 갖지 않는 노드 |
| Internal Node | 중간마디 | 부모와 자식을 모두 갖는 노드 |
| Branch | 가지 | 뿌리마디로부터 끝마디까지 연결된 가지들 |
| Depth | 깊이 | 뿌리마디부터 끝마디까지 중간마디들의 수 |

### (2) 의사결정트리 특징

#### 장점

- 이해하기 쉬운 규칙이 생성된다. (`if~else`)
- 분류예측에 유용하지만 회귀예측도 가능 (범주형, 연속형 모두 가능)
- 어느 변수가 상대적으로 더 중요한지 확인 가능
- 비교적 빠른 의사결정이 가능

#### 단점

- 연속형 변수값을 예측(회귀)할 때 예측력이 떨어짐(적당하지 않다.)
- 트리가 복잡할 수록 예측력 저하, 해석이 어려움
- 상황에 따라 계산량이 많아서 처리속도 느림
- 안정성이 떨어짐(데이터에 약간의 변형이 있는 경우 결과가 나빠질 수 있음)

### (3) 의사결정트리 진행 절차

#### 프로세스

##### step1

아래와 같이 데이터를 가장 잘 구분할 수 있는 질문을 기준으로 나눈다

![tree](res/tree03-1.png)

변수 중 하나인 xi가 선택되고 xi의 값 즉, si(분할기준)가 p차원의 공간을 두 개의 부분으로 나누도록 선정 

$$xi \Rightarrow (xi<=si) ∪ (xi>si)$$

##### step2

나뉜 각 범주에서 또 다시 데이터를 가장 잘 구분할 수 있는 질문을 기준으로 나눈다.

원하는 순수도에 도달할 때 까지 반복 수행

![tree](res/tree03-2.png)

##### 주의

데이터를 나누는 작업을 지나치게 많이 하면 오버피팅이 발생한다.

결정 트리에 아무 파라미터를 주지 않고 모델링하면 오버피팅된다.

![tree](res/tree03-3.png)

#### 의사결정트리 분리

| 구분 | 내용 |
|---|---|
| 반복적 분할 | 훈련용 데이터를 이용하여 독립변수의 차원공간을 반복적으로 분할 |
| 가지치기 | 평가용 데이터를 이용하여 가지치기를 수행 |
| 분할기준 | 부모마디보다 자식마디의 순수도가 증가하도록 분류를 형성 특정 범주의 개체들이 포함 되어 있는 정도 |

순수한 데이터의 비율이 높을수록 완벽한 트리가 됨

![tree](res/tree04.png)

#### 반복적 분리 과정

- 모든 공간을 직사각형으로 나누어서 각 직사각형이 가능한 한 ‘순수(Pure)’하게 동질적(Homogenous)이 되도록 하는 것
- 최종 직사각형에 포함된 변수가 모두 동일한 집단에 속하는 것

![tree](res/tree05.png)


### (4) 사용 예시

- 은행에서 대출 가능여부 판단
- 환자가 어떠한 조건에 부합하여 병에 걸렸는가에 대한 내용
  