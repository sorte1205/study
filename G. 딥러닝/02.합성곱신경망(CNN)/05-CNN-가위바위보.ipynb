{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN - 가위바위보\n",
    "\n",
    "[https://www.kaggle.com/datasets/drgfreeman/rockpaperscissors](https://www.kaggle.com/datasets/drgfreeman/rockpaperscissors) 에서 배포하는 데이터셋\n",
    "\n",
    "아래 URL을 통해 기본 파일 정리가 수행된 파일을 내려 받는다.\n",
    "\n",
    "> [https://drive.google.com/file/d/1x6YsEBCSuxAKbmUbF-U0ntXoNwELoTVr/view?usp=sharing](https://drive.google.com/file/d/1x6YsEBCSuxAKbmUbF-U0ntXoNwELoTVr/view?usp=sharing)\n",
    "\n",
    "## #01. 준비작업 \n",
    "\n",
    "### [1] 패키지 참조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연결된 모듈이 업데이트 되면 즉시 자동 로드함\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "from hossam.util import *\n",
    "from hossam.plot import *\n",
    "from hossam.tensor import *\n",
    "\n",
    "import zipfile\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2] 데이터셋 준비하기\n",
    "\n",
    "#### (1) 파일 압축 해제\n",
    "\n",
    "데이터셋을 캐글로부터 다운로드 받은 후 적절한 위치에 압축을 해제한다.\n",
    "\n",
    "압축을 해제하면 cats 폴더와 dogs 폴더에 각각 5000장의 이미지가 포함되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 압축파일의 경로\n",
    "workspace_dir = \"E:\\\\DataScience\\\\MainCourse\\\\G. 딥러닝\\\\02.합성곱신경망(CNN)\"\n",
    "file_path = os.path.join(workspace_dir, \"rock-paper-scissors.zip\")\n",
    "\n",
    "# 압축을 해제할 경로\n",
    "extract_dir = os.path.join(workspace_dir, \"rock-paper-scissors\")\n",
    "\n",
    "# 해당 폴더가 없다면 폴더를 생성하고 파일의 압축을 해제\n",
    "if not os.path.exists(extract_dir):\n",
    "    os.mkdir(extract_dir)\n",
    "\n",
    "    zip_ref = zipfile.ZipFile(file_path, \"r\")\n",
    "    zip_ref.extractall(extract_dir)\n",
    "    zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) 임의의 이미지 확인\n",
    "\n",
    "#####  이미지\n",
    "\n",
    "실행시마다 표시 이미지가 랜덤하게 바뀐다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir = os.listdir(extract_dir)\n",
    "subdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in subdir:\n",
    "    path = os.path.join(extract_dir, s)\n",
    "    print(path)\n",
    "\n",
    "    image_list = os.listdir(path)\n",
    "    image_count = len(image_list)\n",
    "\n",
    "    rand = np.random.random_integers(0, image_count - 1, 5)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 5, figsize=(20, 3), dpi=100)\n",
    "\n",
    "    for i in range(0, len(ax)):\n",
    "        file_path = os.path.join(path, image_list[rand[i]])\n",
    "        img = load_image(file_path)\n",
    "        ax[i].imshow(img)\n",
    "        ax[i].axis(\"off\")\n",
    "        ax[i].set_title(image_list[rand[i]])\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #02. 이미지 데이터 전처리\n",
    "\n",
    "### [1] 이미지 전처리기 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,  # 정규화(색상값을 0~1사이로 변경함)\n",
    "    rotation_range=30,  # 이미지 무작위 회전 (30도 이내)\n",
    "    width_shift_range=0.2,  # 가로 방향 이동 범위 (무작위 20% 이내)\n",
    "    height_shift_range=0.2,  # 세로 방향 이동 범위 (무작위 20% 이내)\n",
    "    shear_range=0.2,  # 층 밀리기 강도 (무작위 20% 이내)\n",
    "    zoom_range=0.2,  # 줌 범위 (무작위 20% 이내)\n",
    "    brightness_range=[0.5, 1.0],  # 이미지 밝기\n",
    "    horizontal_flip=True,  # 수평 뒤집기\n",
    "    vertical_flip=True,  # 수직 뒤집기\n",
    "    fill_mode=\"nearest\",  # 이미지 변형 시 채울 픽셀\n",
    "    validation_split=0.2,  # 검증 데이터 비율\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2] 이미지 데이터 전처리 수행\n",
    "\n",
    "#### (1) 훈련용 이미지 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = os.listdir(extract_dir)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = image_gen.flow_from_directory(\n",
    "    extract_dir,  # 이미지 파일이 위치한 폴더\n",
    "    classes=classes,  # 분류할 클래스명\n",
    "    batch_size=16,  # 배치 사이즈\n",
    "    class_mode=\"categorical\",  # 다항분류용임을 명시(binary or categorical)\n",
    "    target_size=(64, 64),  # 변환될 이미지 해상도\n",
    "    shuffle=True,  # 이미지 섞기\n",
    "    color_mode=\"rgb\",  # 컬러 이미지\n",
    "    seed=get_random_state(),  # 랜덤 시드값\n",
    "    subset=\"training\",  # 훈련용 데이터 생성임을 명시\n",
    ")\n",
    "\n",
    "train_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) 검증용 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = image_gen.flow_from_directory(\n",
    "    extract_dir,  # 이미지 파일이 위치한 폴더\n",
    "    classes=classes,  # 분류할 클래스명\n",
    "    batch_size=16,  # 배치 사이즈\n",
    "    class_mode=\"categorical\",  # 다항분류용임을 명시(binary or categorical)\n",
    "    target_size=(64, 64),  # 변환될 이미지 해상도\n",
    "    shuffle=True,  # 이미지 섞기\n",
    "    color_mode=\"rgb\",  # 컬러 이미지\n",
    "    seed=get_random_state(),  # 랜덤 시드값\n",
    "    subset=\"validation\",  # 검증용 데이터 생성임을 명시\n",
    ")\n",
    "\n",
    "test_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #03. 훈련 모델 적합\n",
    "\n",
    "### [1] 모델 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf_create(\n",
    "    layer=[\n",
    "        # cnn (1)\n",
    "        {\n",
    "            \"type\": \"conv2d\",\n",
    "            \"filters\": 16,\n",
    "            \"kernel_size\": 6,\n",
    "            \"padding\": \"same\",\n",
    "            \"input_shape\": (64, 64, 3),\n",
    "        },\n",
    "        {\"type\": \"batchnorm\"},\n",
    "        {\"type\": \"activation\", \"function\": \"relu\"},\n",
    "        {\"type\": \"maxpooling\", \"pool_size\": (2, 2)},\n",
    "        {\"type\": \"dropout\", \"rate\": 0.1},\n",
    "        # cnn (2)\n",
    "        {\n",
    "            \"type\": \"conv2d\",\n",
    "            \"filters\": 32,\n",
    "            \"kernel_size\": 5,\n",
    "            \"padding\": \"same\",\n",
    "        },\n",
    "        {\"type\": \"batchnorm\"},\n",
    "        {\"type\": \"activation\", \"function\": \"relu\"},\n",
    "        {\"type\": \"maxpooling\", \"pool_size\": (2, 2)},\n",
    "        {\"type\": \"dropout\", \"rate\": 0.1},\n",
    "        # cnn (3)\n",
    "        {\n",
    "            \"type\": \"conv2d\",\n",
    "            \"filters\": 64,\n",
    "            \"kernel_size\": 4,\n",
    "            \"padding\": \"same\",\n",
    "        },\n",
    "        {\"type\": \"batchnorm\"},\n",
    "        {\"type\": \"activation\", \"function\": \"relu\"},\n",
    "        {\"type\": \"maxpooling\", \"pool_size\": (2, 2)},\n",
    "        {\"type\": \"dropout\", \"rate\": 0.1},\n",
    "        # cnn (4)\n",
    "        {\n",
    "            \"type\": \"conv2d\",\n",
    "            \"filters\": 128,\n",
    "            \"kernel_size\": 3,\n",
    "            \"padding\": \"same\",\n",
    "        },\n",
    "        {\"type\": \"batchnorm\"},\n",
    "        {\"type\": \"activation\", \"function\": \"relu\"},\n",
    "        {\"type\": \"maxpooling\", \"pool_size\": (2, 2)},\n",
    "        {\"type\": \"dropout\", \"rate\": 0.1},\n",
    "        # 단일층\n",
    "        {\"type\": \"flatten\"},\n",
    "        {\"type\": \"dense\", \"units\": 64},\n",
    "        {\"type\": \"batchnorm\"},\n",
    "        {\"type\": \"activation\", \"function\": \"relu\"},\n",
    "        {\"type\": \"dense\", \"units\": 3},  # 출력층의 수는 클래스의 수와 동일해야 함\n",
    "        {\"type\": \"batchnorm\"},\n",
    "        {\"type\": \"activation\", \"function\": \"softmax\"},  # 다중클래스 분류용 활성화 함수\n",
    "    ],\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",  # 다중클래스 분류용 손실함수\n",
    "    metrics=[\"acc\"],\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2] 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "result = tf_train(\n",
    "    model=model,\n",
    "    x_train=train_set,\n",
    "    x_test=test_set,\n",
    "    epochs=1000,\n",
    "    steps_per_epoch=train_set.samples // batch_size,\n",
    "    validation_steps=test_set.samples // batch_size,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "tf_result(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #04. 학습 결과 확인\n",
    "\n",
    "### [1] 검증 데이터의 라벨 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = test_set.classes\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2] 검증 데이터에 대한 예측값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict(test_set)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3] 혼동 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_confusion_matrix(y, y_pred, figsize=(5, 5), dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #05. 학습 결과 적용\n",
    "\n",
    "### [1] 임의의 이미지 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "가위_img = load_image(\"res/가위.jpg\")\n",
    "가위_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "바위_img = load_image(\"res/바위.jpg\")\n",
    "바위_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "보_img = load_image(\"res/보.jpg\")\n",
    "보_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2] 이미지 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터와 동일한 크기로 리사이즈\n",
    "가위_tune = tune_image(가위_img, size=(64, 64), contrast=1.5)\n",
    "바위_tune = tune_image(바위_img, size=(64, 64), contrast=1.5)\n",
    "보_tune = tune_image(보_img, size=(64, 64), contrast=1.5)\n",
    "\n",
    "# 이미지 데이터 변환\n",
    "가위_flow = image_gen.flow(np.array([가위_tune]))\n",
    "바위_flow = image_gen.flow(np.array([바위_tune]))\n",
    "보_flow = image_gen.flow(np.array([보_tune]))\n",
    "\n",
    "# 예측값 생성\n",
    "가위_pred_proba = model.predict(가위_flow)\n",
    "가위_pred = np.argmax(가위_pred_proba)\n",
    "print(가위_pred_proba, 가위_pred)\n",
    "\n",
    "바위_pred_proba = model.predict(바위_flow)\n",
    "바위_pred = np.argmax(바위_pred_proba)\n",
    "print(바위_pred_proba, 바위_pred)\n",
    "\n",
    "보_pred_proba = model.predict(보_flow)\n",
    "보_pred = np.argmax(보_pred_proba)\n",
    "print(보_pred_proba, 보_pred)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
