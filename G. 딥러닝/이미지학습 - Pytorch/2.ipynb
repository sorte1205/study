{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model.py 구성\n",
    "\n",
    "1. layer 정의 부분\n",
    "2. network forward 부분\n",
    "forward만 바꿔주면 nn.module에 따라 backward는 그에 맞게 바뀜.\n",
    "backward를 따로 지정할 수 있기도 함.\n",
    "\n",
    "그러나 보통 init과 forward만 건드리면 됨.\n",
    "init: 레이어들 몇 개인지, w와 b를 정의하는 것\n",
    "forward: W와 b를 어떤 식으로 연산을 할 것인지 정의.\n",
    "\n",
    "파라미터가 없는 함수를 보통 F에서 가져옴\n",
    "\n",
    "init에서 \"\"nn.Conv2d(2,3,5)\"\" 이 과정에서, 파라미터 뿐 아니라 연산하는 방법까지 정의가 됨.\n",
    "    Add = +\n",
    "    Sub = - \n",
    "forward는 연산과, 각 연산의 순서를 정의하는 것.\n",
    "    x = add(x,1)\n",
    "    x = sub(x,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn # 네트워크 모듈 정의에 씀\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">네트워크 구조: image-to-class task\n",
    "\n",
    "Feature learning\n",
    "convolution: 특징 (feature)을 추출하기 위한 구조\n",
    "pooling: 특징(feature)을 압축하기 위한 구조. feature 채널 갯수 줄이기\n",
    "fully connected layer: 특징을 통해 얻고자하는 정보를 연산하는 구조\n",
    "\n",
    "\n",
    "Classification \n",
    "flatten                    여기서부턴 3차원 구조를 벡터 형태로.\n",
    "full;y connected    데이터 값 마다 모두 연결, 각 위치마다 W가 있는 구조.\n",
    "softmax 분류\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ">네트워크 구조: image-to-image task\n",
    "\n",
    "이미지에서 다시 원래 이미지로 복원\n",
    "\n",
    "feature learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution : 합성곱 연산\n",
    "\n",
    "얼마나 유사한 지를 연산\n",
    "각각 곱해서 더한 값 -> \n",
    "4 by 4 와 3 by 3의 합성곱은 2by 2가 나온다.\n",
    "\n",
    "여기서 3 by 3이 필터 역할.\n",
    "필터는 학습해야하는 파라미터 역할을 하는 것. \n",
    "필터는 처음에는 랜덤한 값.\n",
    "2d 이미지의 필터 통과한 결과인 output array \n",
    "\n",
    "\n",
    "2가지의  convolution정의\n",
    "\n",
    "conv: input, out channel수, kernel size는 정의해줘야함.\n",
    "    kernel size는 필터의 크기. \n",
    "                3번째 파라미터: 3->3 by 3 / (3,5) -> 3 by 5. 보통은 정방형을 많이 씀. )\n",
    "    input channel 수:\n",
    "                1반쩨 피라미터: ex. 이미지는 RGB -> 3개 채널. \n",
    "                필터는 인풋채널 갯수만큼의씩의 한 묶음으로 되어있음./ \n",
    "                각 묶음수는 output 채널 수 만큼 있다. \n",
    "                (긱 믂음 안의 필터는 같으나, 다른 묶음은 서로 다른 필터.)\n",
    "    output channel 수:\n",
    "                2반쩨 파라미터:\n",
    "                output으로 몇 개의 채널으로 내보내고 싶은지 정할 수 있음.\n",
    "                이 아웃풋의 결과는 다시 convolution의 input이 될 수 있어, 그 다음의 input channel은 output channel의 수와 같게 됨,\n",
    "\n",
    "\n",
    "        \n",
    "functional.conv : conv 자체를 정의\n",
    "\n",
    "\n",
    "striding과 padding은 종종 바꿈\n",
    "    stride: 몇 칸 씩 움직이는지. 1이 기본 값.\n",
    "                output 의 가로, 세로 사이즈를 줄이고 싶을 때, stride를 늘리기도 함.\n",
    "                pooling을 그 대신 쓰기도 한다고?\n",
    "    pooling: 데이터 압축.\n",
    "                max pooling : 가장 유의미한 값을 가져온다\n",
    "                average pooling: 평균 값을 가져온다\n",
    "                stride를 window kernel size로 줘야함.\n",
    "    padding: output의 중심값이 포함할 수 있는 값을 늘릴 수 있음.\n",
    "                    output도 input의 크기와 동일하게 맞출 수 있음\n",
    "                    kernel size는 보통 홀수를 많이 하고, \n",
    "                        kernel이 3by3이면 1칸, 5by5면 2칸씩 패딩으로 0값을 줌.\n",
    "                        symmetric, constant 등 어떤 값으로 채울지가 다름.\n",
    "                        가장자리 값으로 채우면, 튀는 값을 방지.\n",
    "                        주요 요인은 아님.\n",
    "bias = True라면, output각각마다 bias가 있게 됨.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maxpool2d\n",
    "\n",
    "input = torch.radn(20, 16, 50, 32)\n",
    "랜덤한 배치사이즈 ?\n",
    "1. 20개의 데이터가 한번에 들어옴\n",
    "2. 16채널\n",
    "3. 가로 50\n",
    "4. 세로 32\n",
    "\n",
    "\n",
    "maxpool2d(윈도우, stride)\n",
    "\n",
    "\n",
    "linear = fully connected layer\n",
    "torch.nn.linear(input feature (데이터) 갯수, output feature의 갯수. bias=True, )\n",
    "inputfeature 갯수 by outputfeature 갯수인 \n",
    "\n",
    "input  = torch.radn(128, 20)\n",
    "128은 배치 사이즈\n",
    "20은 채널 수\n",
    "\n",
    "\n",
    "flatten(x,1) -> 1차로 펴줄 것\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization layer -> skip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actovation Layer\n",
    "\n",
    "많이 쓰는 activation 함수가 Relu.\n",
    "-> 음수에서는 0을 내보내고, 양수는 값 그대로 나오게 함 (0과 값 중 max를 출력)\n",
    "-> F.relu로 바로 쓰기도 함\n",
    "prelu\n",
    "-> 음수에서도 선형 기울기가 있는 일차함수그래프, 양수는 그대로 (max(0,x) +alpha*min(0,x))\n",
    "    \n",
    "softmax\n",
    "-> 모든 벡터 값들의 exponential 값\n",
    "-> 1 5 3\n",
    "->< e^1 e^5 e^3 -> 각 값을 더했을 때 1이 되도록 분모를 각각의 총 합으로취해줌\n",
    "-> m =nn.Softmax(1, 5, 3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[정리] 자주 쓰는 함수 들\n",
    "\n",
    "CNN : \t\tnn.Conv2d(in_ch, out_ch, k_size, stride=1)\n",
    "MaxPool :  \tnn.MaxPool2d(k_size, stride=None)\n",
    "FC:\t\t\tnn.Linear(in_feat, out_feat)\n",
    "Normalize:\tnn.BatchNorm2d(num_feat)\n",
    "Activation: \tnn.ReLU()\n",
    "\t\t            \tnn.Softmax(dim)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "과제1\n",
    "\n",
    "    파이토치 튜토리얼 직접 실행해보기.\n",
    "\n",
    "과제2\n",
    "\n",
    "    그림만 보고 코드 짜보기"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myAnaconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
